{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19da090e-4a09-408c-8840-41c021884143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 12:35:35.995755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-08 12:35:41.510822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data import get_data, fetching_run\n",
    "from models import ClassifierNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.argparser import build_parser\n",
    "from datasets import CHEXPERT_remedis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6356ed-675e-4ef6-8a46-eb8a8a48825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_knn(K, x_train, y_train, x_test, y_test, weights=\"uniform\"):\n",
    "    if len(x_train)<K:\n",
    "        auc=None\n",
    "    else:\n",
    "        model= KNeighborsClassifier(n_neighbors=K, weights=weights)\n",
    "        #weights \"uniform\" or \"distance\"\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred= model.predict(x_test)\n",
    "        auc= tf.keras.metrics.AUC(multi_label=True)(y_test, y_pred).numpy()\n",
    "    return auc\n",
    "\n",
    "def get_auc_continuous_knn(K, x_train, y_train, x_valid, y_valid, x_test, y_test, weights=\"uniform\"):\n",
    "    if len(x_train)<K:\n",
    "        auc=None\n",
    "    else:\n",
    "        model= KNeighborsClassifier(n_neighbors=K, weights=weights)\n",
    "        #weights \"uniform\" or \"distance\"\n",
    "        model.fit(x_train, y_train)\n",
    "        model.classes_= [np.array([0., 1.]),\n",
    "                         np.array([0., 1.]),\n",
    "                         np.array([0., 1.]),\n",
    "                         np.array([0., 1.]),\n",
    "                         np.array([0., 1.])]\n",
    "        y_pred = model.predict_proba(x_test)\n",
    "        y_pred = np.array(y_pred)[:,:,1]\n",
    "        y_pred = np.moveaxis(y_pred, 0, 1)\n",
    "        auc= tf.keras.metrics.AUC(multi_label=True)(y_test, y_pred).numpy()\n",
    "    return auc\n",
    "    \n",
    "def get_auc_mlp(x_train, y_train, x_valid, y_valid, x_test, y_test, lr_init=0.001, n_epochs=100, patience=10):\n",
    "    SHUFFLE_BUFFER_SIZE=128\n",
    "    BATCH_SIZE=64\n",
    "    \n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    ds_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "\n",
    "    ds_train = ds_train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    ds_test = ds_test.batch(BATCH_SIZE)\n",
    "    ds_valid = ds_valid.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        # tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        # tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(5),\n",
    "        tf.keras.layers.Activation('sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        # tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        # tf.keras.layers.Dense(512, activation='relu'),\n",
    "        # tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(5),\n",
    "        tf.keras.layers.Activation('sigmoid'),\n",
    "    ])\n",
    "\n",
    "    \n",
    "\n",
    "    model.build([None, 2048])\n",
    "    \n",
    "    # https://stackoverflow.com/questions/62350538/tf2-2-loading-a-saved-model-from-tensorflow-hub-failed-with-attributeerror\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate= lr_init)    \n",
    "    model.compile(optimizer= optimizer, \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics = [tf.keras.metrics.AUC(from_logits=False, multi_label= True)])\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                patience=patience, \n",
    "                                                baseline=None, \n",
    "                                                start_from_epoch= 10)\n",
    "    \n",
    "    # Fitting the model\n",
    "    history_train = model.fit(ds_train,\n",
    "                              verbose=1, \n",
    "                              epochs=n_epochs,\n",
    "                              validation_data= ds_valid,\n",
    "                              validation_freq= 1,\n",
    "                              callbacks=[callback], \n",
    "                             )\n",
    "    history_train= pd.DataFrame.from_dict(history_train.history)\n",
    "\n",
    "    #Evaluating the model\n",
    "    history_test = model.evaluate(ds_test, verbose=0)\n",
    "\n",
    "    return history_train, history_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80ae2f1-9962-456f-97a7-8aae507abb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args= pd.Series({\n",
    "    \"dataset\":\"chexpert\",\n",
    "    \"algorithm\":\"full\",\n",
    "    \"sd\":1,\n",
    "    \"gamma\":0.5,\n",
    "    \"tsh\":0.95,\n",
    "    \"hard_thresholding\":\"False\",\n",
    "    \"separable\":\"not\",\n",
    "    \"n_epochs\":1000,\n",
    "    \"running_cluster\":\"True\",\n",
    "    \"run\":\"chexpert_runs\",\n",
    "    \"budget\":\"low\",\n",
    "    })\n",
    "\n",
    "# args = build_parser().parse_args(tuple(sys.argv[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274e03e-cebf-4c04-8cd5-9b2fec78013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 12:35:56.689359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:35:56.820608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:35:56.821521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:35:56.823814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:35:56.824941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:35:56.825739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:36:00.180297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:36:00.181094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:36:00.181702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-08 12:36:00.182235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10372 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:00:09.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 12:36:14.237946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14c13c5d12e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-08 12:36:14.238088: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-09-08 12:36:14.387705: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-08 12:36:18.635172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-09-08 12:36:18.990588: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-08 12:36:19.226170: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142/3142 [==============================] - 24s 5ms/step - loss: 0.5138 - auc: 0.6512 - val_loss: 0.5011 - val_auc: 0.6905\n",
      "Epoch 2/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.5035 - auc: 0.6753 - val_loss: 0.4963 - val_auc: 0.6991\n",
      "Epoch 3/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.5010 - auc: 0.6807 - val_loss: 0.4941 - val_auc: 0.7031\n",
      "Epoch 4/100\n",
      "3142/3142 [==============================] - 16s 5ms/step - loss: 0.4995 - auc: 0.6836 - val_loss: 0.4927 - val_auc: 0.7056\n",
      "Epoch 5/100\n",
      "3142/3142 [==============================] - 16s 5ms/step - loss: 0.4985 - auc: 0.6857 - val_loss: 0.4916 - val_auc: 0.7073\n",
      "Epoch 6/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4978 - auc: 0.6872 - val_loss: 0.4909 - val_auc: 0.7087\n",
      "Epoch 7/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4972 - auc: 0.6885 - val_loss: 0.4902 - val_auc: 0.7098\n",
      "Epoch 8/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4967 - auc: 0.6895 - val_loss: 0.4898 - val_auc: 0.7108\n",
      "Epoch 9/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4963 - auc: 0.6904 - val_loss: 0.4892 - val_auc: 0.7115\n",
      "Epoch 10/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4959 - auc: 0.6911 - val_loss: 0.4889 - val_auc: 0.7122\n",
      "Epoch 11/100\n",
      "3142/3142 [==============================] - 13s 4ms/step - loss: 0.4956 - auc: 0.6918 - val_loss: 0.4884 - val_auc: 0.7128\n",
      "Epoch 12/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4953 - auc: 0.6923 - val_loss: 0.4882 - val_auc: 0.7134\n",
      "Epoch 13/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4950 - auc: 0.6929 - val_loss: 0.4879 - val_auc: 0.7139\n",
      "Epoch 14/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4948 - auc: 0.6933 - val_loss: 0.4876 - val_auc: 0.7144\n",
      "Epoch 15/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4946 - auc: 0.6938 - val_loss: 0.4873 - val_auc: 0.7147\n",
      "Epoch 16/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4944 - auc: 0.6942 - val_loss: 0.4870 - val_auc: 0.7152\n",
      "Epoch 17/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4942 - auc: 0.6946 - val_loss: 0.4869 - val_auc: 0.7154\n",
      "Epoch 18/100\n",
      "3142/3142 [==============================] - 16s 5ms/step - loss: 0.4940 - auc: 0.6949 - val_loss: 0.4866 - val_auc: 0.7158\n",
      "Epoch 19/100\n",
      "3142/3142 [==============================] - 17s 6ms/step - loss: 0.4938 - auc: 0.6953 - val_loss: 0.4864 - val_auc: 0.7161\n",
      "Epoch 20/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4937 - auc: 0.6955 - val_loss: 0.4864 - val_auc: 0.7164\n",
      "Epoch 21/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4936 - auc: 0.6958 - val_loss: 0.4861 - val_auc: 0.7166\n",
      "Epoch 22/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4934 - auc: 0.6961 - val_loss: 0.4859 - val_auc: 0.7169\n",
      "Epoch 23/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4933 - auc: 0.6964 - val_loss: 0.4859 - val_auc: 0.7171\n",
      "Epoch 24/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4932 - auc: 0.6966 - val_loss: 0.4857 - val_auc: 0.7174\n",
      "Epoch 25/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4930 - auc: 0.6968 - val_loss: 0.4855 - val_auc: 0.7176\n",
      "Epoch 26/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4929 - auc: 0.6971 - val_loss: 0.4854 - val_auc: 0.7177\n",
      "Epoch 27/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4928 - auc: 0.6972 - val_loss: 0.4853 - val_auc: 0.7179\n",
      "Epoch 28/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4927 - auc: 0.6975 - val_loss: 0.4852 - val_auc: 0.7181\n",
      "Epoch 29/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4926 - auc: 0.6977 - val_loss: 0.4850 - val_auc: 0.7182\n",
      "Epoch 30/100\n",
      "3142/3142 [==============================] - 14s 5ms/step - loss: 0.4925 - auc: 0.6978 - val_loss: 0.4850 - val_auc: 0.7185\n",
      "Epoch 31/100\n",
      "3142/3142 [==============================] - 17s 5ms/step - loss: 0.4925 - auc: 0.6980 - val_loss: 0.4848 - val_auc: 0.7186\n",
      "Epoch 32/100\n",
      "3142/3142 [==============================] - 17s 6ms/step - loss: 0.4924 - auc: 0.6981 - val_loss: 0.4848 - val_auc: 0.7187\n",
      "Epoch 33/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4923 - auc: 0.6983 - val_loss: 0.4846 - val_auc: 0.7189\n",
      "Epoch 34/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4922 - auc: 0.6984 - val_loss: 0.4845 - val_auc: 0.7191\n",
      "Epoch 35/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4921 - auc: 0.6986 - val_loss: 0.4845 - val_auc: 0.7192\n",
      "Epoch 36/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4921 - auc: 0.6988 - val_loss: 0.4845 - val_auc: 0.7193\n",
      "Epoch 37/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4920 - auc: 0.6989 - val_loss: 0.4843 - val_auc: 0.7194\n",
      "Epoch 38/100\n",
      "3142/3142 [==============================] - 18s 6ms/step - loss: 0.4919 - auc: 0.6990 - val_loss: 0.4843 - val_auc: 0.7196\n",
      "Epoch 39/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4919 - auc: 0.6991 - val_loss: 0.4842 - val_auc: 0.7196\n",
      "Epoch 40/100\n",
      "3142/3142 [==============================] - 16s 5ms/step - loss: 0.4918 - auc: 0.6993 - val_loss: 0.4841 - val_auc: 0.7198\n",
      "Epoch 41/100\n",
      "3142/3142 [==============================] - 17s 5ms/step - loss: 0.4917 - auc: 0.6994 - val_loss: 0.4841 - val_auc: 0.7199\n",
      "Epoch 42/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4917 - auc: 0.6995 - val_loss: 0.4840 - val_auc: 0.7200\n",
      "Epoch 43/100\n",
      "3142/3142 [==============================] - 14s 4ms/step - loss: 0.4916 - auc: 0.6996 - val_loss: 0.4839 - val_auc: 0.7200\n",
      "Epoch 44/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4915 - auc: 0.6998 - val_loss: 0.4839 - val_auc: 0.7202\n",
      "Epoch 45/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4915 - auc: 0.6999 - val_loss: 0.4837 - val_auc: 0.7203\n",
      "Epoch 46/100\n",
      "3142/3142 [==============================] - 15s 5ms/step - loss: 0.4914 - auc: 0.7000 - val_loss: 0.4837 - val_auc: 0.7203\n",
      "Epoch 47/100\n",
      "2698/3142 [========================>.....] - ETA: 2s - loss: 0.4910 - auc: 0.7001"
     ]
    }
   ],
   "source": [
    "if args.sd is not None:\n",
    "    np.random.seed(args.sd)\n",
    "\n",
    "dataset, dataset_test, run_path, idx = get_data(args)\n",
    "dataset_valid = CHEXPERT_remedis(type=\"valid\", cluster=args.running_cluster)\n",
    "scores, queries, radiuses, degrees, options, covers= fetching_run(args.algorithm, run_path)\n",
    "\n",
    "x_test, y_test = dataset_test.get_all_data()\n",
    "x_valid, y_valid = dataset_test.get_all_data()\n",
    "aucs= pd.DataFrame(columns= [\"5_NN\", \"20_NN\", \"100_NN\", \"5_NN_continuous\", \"20_NN_continuous\", \"100_NN_continuous\", \"mlp\"])\n",
    "\n",
    "if args.algorithm==\"full\":\n",
    "    x_train, y_train = dataset.get_all_data()\n",
    "    # auc5=  get_auc_knn(5, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    # auc20=  get_auc_knn(20, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    # auc100=  get_auc_knn(100, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    \n",
    "    # auc5_cont=  get_auc_continuous_knn(5, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    # auc20_cont=  get_auc_continuous_knn(20, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    # auc100_cont=  get_auc_continuous_knn(100, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    # print(auc5, auc20, auc100, auc5_cont, auc20_cont, auc100_cont)\n",
    "    _, history_test= get_auc_mlp(x_train, y_train, x_valid, y_valid, x_test, y_test, lr_init=0.001, n_epochs=100)\n",
    "    new_row = {\"5_NN\":auc5, \"20_NN\":auc20, \"100_NN\":auc100, \n",
    "               \"5_NN_continuous\":auc5_cont, \"20_NN_continuous\":auc20_cont, \"100_NN_continuous\":auc100_cont, \"mlp\": history_test[-1]}\n",
    "    aucs = pd.concat([aucs, pd.DataFrame([new_row])], ignore_index=True)\n",
    "else:\n",
    "    for i in range(len(idx)):  \n",
    "        dataset.restart()\n",
    "        dataset.observe(queries[:idx[i]])\n",
    "        x_train, y_train = dataset.get_labeled_data()\n",
    "        auc5=  get_auc_knn(5, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "        auc20=  get_auc_knn(20, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "        auc100=  get_auc_knn(100, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "        \n",
    "        auc5_cont=  get_auc_continuous_knn(5, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "        auc20_cont=  get_auc_continuous_knn(20, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "        auc100_cont=  get_auc_continuous_knn(100, x_train, y_train, x_test, y_test, weights=\"distance\")\n",
    "    \n",
    "        _, history_test= get_auc_mlp(x_train, y_train, x_test, y_test, lr_init=0.001, n_epochs=100)\n",
    "        new_row = {\"5_NN\":auc5, \"20_NN\":auc20, \"100_NN\":auc100, \n",
    "                   \"5_NN_continuous\":auc5_cont, \"20_NN_continuous\":auc20_cont, \"100_NN_continuous\":auc100_cont, \"mlp\": history_test[-1]}\n",
    "        aucs = pd.concat([aucs, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        print(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d7911eb1-344e-4192-b3ba-aa1a74e46b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/work/grlab/projects/projects2022_doctor-in-the-loop/chexpert_runs/chexpert/1000_0.95_1/evaluation.csv'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_path+\"/evaluation.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
